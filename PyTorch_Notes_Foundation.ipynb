{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30558,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-12-24T01:43:32.505247Z",
          "iopub.execute_input": "2023-12-24T01:43:32.506055Z",
          "iopub.status.idle": "2023-12-24T01:43:36.875222Z",
          "shell.execute_reply.started": "2023-12-24T01:43:32.506015Z",
          "shell.execute_reply": "2023-12-24T01:43:36.873072Z"
        },
        "trusted": true,
        "id": "LD4Xh-TmcVLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Types of torch.nn Layers + torch.optim Optimization function + torch.nn Loss function"
      ],
      "metadata": {
        "id": "ILvvpXPVcVLj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-24T02:01:09.208256Z",
          "iopub.execute_input": "2023-12-24T02:01:09.208656Z",
          "iopub.status.idle": "2023-12-24T02:01:09.218551Z",
          "shell.execute_reply.started": "2023-12-24T02:01:09.208624Z",
          "shell.execute_reply": "2023-12-24T02:01:09.217026Z"
        },
        "trusted": true,
        "id": "IUAok_WUcVLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Tensors"
      ],
      "metadata": {
        "id": "voPfW2tXcVLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "np_array = np.array([[1,2],[3,4]])\n",
        "torch_array = torch.from_numpy(np_array)\n",
        "print(f\"torch_array : {torch_array}\")\n",
        "torch_ones = torch.ones_like(torch_array,dtype=torch.float)\n",
        "print(f\"torch_ones : {torch_ones}\")\n",
        "shape = (2,3)\n",
        "torch_rand = torch.rand(shape)\n",
        "print(f\"torch_rand : {torch_rand}\")\n",
        "torch_arange = torch.arange(start=1,end=11,step=2)\n",
        "print(f\"torch_arange : \",{torch_arange})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T02:32:00.460019Z",
          "iopub.execute_input": "2023-12-28T02:32:00.460489Z",
          "iopub.status.idle": "2023-12-28T02:32:00.472597Z",
          "shell.execute_reply.started": "2023-12-28T02:32:00.460457Z",
          "shell.execute_reply": "2023-12-28T02:32:00.471136Z"
        },
        "trusted": true,
        "id": "ivC7nF-IcVLv",
        "outputId": "10b8f632-f87d-4a46-804d-088267dd4c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "torch_array : tensor([[1, 2],\n        [3, 4]])\ntorch_ones : tensor([[1., 1.],\n        [1., 1.]])\ntorch_rand : tensor([[0.1420, 0.1922, 0.5319],\n        [0.3657, 0.0430, 0.8208]])\ntorch_arange :  {tensor([1, 3, 5, 7, 9])}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Indexing"
      ],
      "metadata": {
        "id": "N1EXCZjscVLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.reshape(torch.arange(1,13,1,dtype=torch.float),(4,3))\n",
        "print(f\"First row: {x[0]}\")\n",
        "print(f\"First column: {x[:, 0]}\")\n",
        "print(f\"Last column: {x[..., -1]}\")\n",
        "x[:,1] = 0\n",
        "print(x)\n",
        "tensor1 = torch.randn(10, 3, 4)\n",
        "print(tensor1[:,0,0].shape,tensor1[0,:,0].shape,tensor1[0,0,:].shape)\n",
        "print(tensor1)\n",
        "tensor2 = torch.randn(4)\n",
        "print(tensor2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T03:36:55.132456Z",
          "iopub.execute_input": "2023-12-28T03:36:55.133045Z",
          "iopub.status.idle": "2023-12-28T03:36:55.153552Z",
          "shell.execute_reply.started": "2023-12-28T03:36:55.133008Z",
          "shell.execute_reply": "2023-12-28T03:36:55.15176Z"
        },
        "trusted": true,
        "id": "PnxUpt1lcVLz",
        "outputId": "1ebc4dbc-c112-4e82-e632-a4631ec2c004"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "First row: tensor([1., 2., 3.])\nFirst column: tensor([ 1.,  4.,  7., 10.])\nLast column: tensor([ 3.,  6.,  9., 12.])\ntensor([[ 1.,  0.,  3.],\n        [ 4.,  0.,  6.],\n        [ 7.,  0.,  9.],\n        [10.,  0., 12.]])\ntorch.Size([10]) torch.Size([3]) torch.Size([4])\ntensor([[[-0.4198, -1.3901, -0.7433,  1.6252],\n         [-1.3204,  0.2975, -1.9061,  0.4013],\n         [-1.2086, -0.6729,  0.2693, -0.2020]],\n\n        [[-0.2129, -0.5784, -0.1382, -0.1359],\n         [-0.1326,  0.9448, -0.8960, -0.1384],\n         [-1.1900, -0.6642, -0.3136,  0.3689]],\n\n        [[-0.4662, -1.3043, -1.4399,  0.4012],\n         [ 1.5566,  1.7305, -0.0877,  0.4483],\n         [-0.0824, -0.9446, -0.5587, -0.3315]],\n\n        [[ 0.2831, -0.3476,  1.2822,  0.4452],\n         [ 1.3330, -2.1681,  0.7457,  1.1190],\n         [ 0.8063,  0.6081,  0.6591, -0.6953]],\n\n        [[-1.4361,  0.0067,  1.5265,  1.7683],\n         [-1.4769,  0.4061,  0.4140, -1.2963],\n         [-1.4096, -1.4380,  0.1303,  0.6771]],\n\n        [[-0.8026,  0.7763,  0.0867,  1.9739],\n         [-1.0366, -0.0450, -0.6429,  0.3087],\n         [-1.3665, -1.1721, -0.5223,  0.1377]],\n\n        [[ 0.1370, -1.9979,  0.2713, -0.1283],\n         [ 0.6508, -1.1412, -0.3425, -0.6489],\n         [-0.3668,  0.7319,  2.4437, -1.5481]],\n\n        [[-0.0282, -0.0609,  0.3651,  0.7016],\n         [ 0.5137,  0.2146,  1.3256,  0.4319],\n         [-0.4728,  0.4057, -1.1310,  0.3588]],\n\n        [[-1.1598,  1.1433,  0.9422,  0.5403],\n         [ 0.2999, -0.5343, -0.0566,  0.1676],\n         [ 0.8184,  0.7342,  0.3719,  0.0997]],\n\n        [[-0.4189,  0.3068, -0.8246, -0.1423],\n         [ 1.6314,  0.1968,  0.5517, -0.6386],\n         [-1.1487, -1.4260, -0.3797,  1.8733]]])\ntensor([ 0.6858, -0.5195,  0.6868, -0.3207])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Aggreration Operation"
      ],
      "metadata": {
        "id": "ltHg1_8LcVL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(3, 4)\n",
        "print(f\"tensor : {tensor} \\n\")\n",
        "tensor.add_(5)\n",
        "print(\"tensor + 5 (inplace using add_ ) \",tensor)\n",
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(\"tensor concat : \",t1)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T02:35:13.92749Z",
          "iopub.execute_input": "2023-12-28T02:35:13.927959Z",
          "iopub.status.idle": "2023-12-28T02:35:13.938339Z",
          "shell.execute_reply.started": "2023-12-28T02:35:13.927923Z",
          "shell.execute_reply": "2023-12-28T02:35:13.937025Z"
        },
        "trusted": true,
        "id": "AZNMlblzcVL2",
        "outputId": "37e27bae-d6d4-41be-c21e-4518a98f314b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "tensor : tensor([[1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.]]) \n\ntensor + 5 (inplace using add_ )  tensor([[6., 6., 6., 6.],\n        [6., 6., 6., 6.],\n        [6., 6., 6., 6.]])\ntensor concat :  tensor([[6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.],\n        [6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.],\n        [6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.]])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if requires_grad=True then need to detach() before clone()"
      ],
      "metadata": {
        "id": "hvmAWqwDcVL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(2, 2, requires_grad=True) # turn on autograd\n",
        "print(\"a : \",a)\n",
        "\n",
        "b = a.clone()\n",
        "print(\"b : \",b)\n",
        "\n",
        "c = a.detach().clone()\n",
        "print(\"c : \",c)\n",
        "\n",
        "try:\n",
        "    assert b is a\n",
        "except AssertionError as e:\n",
        "    print(e)\n",
        "\n",
        "a = torch.rand(3, 226, 226)\n",
        "e = torch.rand(1,5)\n",
        "c = a.clone()\n",
        "\n",
        "b = a.unsqueeze(0)\n",
        "d = c.squeeze(0)\n",
        "f = e.squeeze(0)\n",
        "print(\"a.unsqueeze(0) : \",a.shape,b.shape)\n",
        "print(\"a.squeeze(0) : \",a.shape,d.shape)\n",
        "print(\"e.squeeze(0) : \",e.shape,f.shape)"
      ],
      "metadata": {
        "id": "r1W9q9mvcVL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torch Aggregation - groupby"
      ],
      "metadata": {
        "id": "AuViruracVL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = torch.Tensor([\n",
        "    [0.1, 0.1],    #-> group / class 1\n",
        "    [0.2, 0.2],    #-> group / class 2\n",
        "    [0.4, 0.4],    #-> group / class 2\n",
        "    [0.0, 0.0]     #-> group / class 0\n",
        "])\n",
        "\n",
        "labels = torch.LongTensor([1,2,2,0])\n",
        "\n",
        "label_size = 3\n",
        "sample_dim = samples.size(1)\n",
        "print(\"sample_dim \",sample_dim)\n",
        "index = labels.unsqueeze(1)\n",
        "print(\"labels.unsqueeze(1) \",index)\n",
        "index = index.repeat((1, sample_dim))\n",
        "print(\"index.repeat((1, sample_dim)) \",index)\n",
        "\n",
        "res = torch.ones(label_size, sample_dim, dtype=samples.dtype)\n",
        "print(\"res \",res)\n",
        "res.scatter_(0, index, samples, reduce='multiply')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T03:13:46.269464Z",
          "iopub.execute_input": "2023-12-28T03:13:46.269971Z",
          "iopub.status.idle": "2023-12-28T03:13:46.287578Z",
          "shell.execute_reply.started": "2023-12-28T03:13:46.269932Z",
          "shell.execute_reply": "2023-12-28T03:13:46.286052Z"
        },
        "trusted": true,
        "id": "QKsnT5qocVL5",
        "outputId": "43fa54bb-fff2-4b34-f17e-0d532f592690"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "sample_dim  2\nlabels.unsqueeze(1)  tensor([[1],\n        [2],\n        [2],\n        [0]])\nindex.repeat((1, sample_dim))  tensor([[1, 1],\n        [2, 2],\n        [2, 2],\n        [0, 0]])\nres  tensor([[1., 1.],\n        [1., 1.],\n        [1., 1.]])\n",
          "output_type": "stream"
        },
        {
          "execution_count": 33,
          "output_type": "execute_result",
          "data": {
            "text/plain": "tensor([[0.0000, 0.0000],\n        [0.1000, 0.1000],\n        [0.0800, 0.0800]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F7rSfwy0cVL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matrix Multiplication\n",
        "\n",
        "    torch.mm - performs a matrix multiplication without broadcasting - (2D tensor) by (2D tensor)\n",
        "    torch.mul - performs a elementwise multiplication with broadcasting - (Tensor) by (Tensor or Number)\n",
        "    torch.matmul - matrix product with broadcasting - (Tensor) by (Tensor) with different behaviors depending on the tensor shapes (dot product, matrix product, batched matrix products).\n",
        "    \n"
      ],
      "metadata": {
        "id": "2JZi5TakcVL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    torch.mm - performs a matrix multiplication without broadcasting\n",
        "It expects two 2D tensors so n×m * m×p = n×p"
      ],
      "metadata": {
        "id": "5SRX46-fcVL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.ones(3, 4)\n",
        "x2 = torch.reshape(torch.arange(1,13,1,dtype=torch.float),(4,3))\n",
        "print(f\"x1 : {x1.shape} ,x2 : {x2.shape}\")\n",
        "y1 = x1 @ x2\n",
        "y2 = x1.matmul(x2)\n",
        "assert torch.all(torch.eq(y1,y2)).item()==True\n",
        "y3 = torch.mm(x1, x2)\n",
        "\n",
        "# assert torch.all(torch.eq(y3,y2)).item()==True\n",
        "print(\"Matrix Multiplication : works with only matching dimensions\")\n",
        "print(f\"y1 = x1 @ x2 : shape {y1.shape} : {y1}\")\n",
        "print(f\"y2 = x1.matmul(x2) : shape {y2.shape} : {y2}\")\n",
        "print(f\"y3 = torch.mm(x1, x2) : shape {y3.shape} : {y3}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T03:48:47.247543Z",
          "iopub.execute_input": "2023-12-28T03:48:47.248082Z",
          "iopub.status.idle": "2023-12-28T03:48:47.260929Z",
          "shell.execute_reply.started": "2023-12-28T03:48:47.248048Z",
          "shell.execute_reply": "2023-12-28T03:48:47.259625Z"
        },
        "trusted": true,
        "id": "SB2H-YS0cVL6",
        "outputId": "455e5e76-e52c-41a7-f127-51fc74c27227"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "x1 : torch.Size([3, 4]) ,x2 : torch.Size([4, 3])\nMatrix Multiplication : works with only matching dimensions\ny1 = x1 @ x2 : shape torch.Size([3, 3]) : tensor([[22., 26., 30.],\n        [22., 26., 30.],\n        [22., 26., 30.]])\ny2 = x1.matmul(x2) : shape torch.Size([3, 3]) : tensor([[22., 26., 30.],\n        [22., 26., 30.],\n        [22., 26., 30.]])\ny3 = torch.mm(x1, x2) : shape torch.Size([3, 3]) : tensor([[22., 26., 30.],\n        [22., 26., 30.],\n        [22., 26., 30.]])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    torch.mul - performs a elementwise multiplication with broadcasting - (Tensor) by (Tensor or Number)\n",
        "\n",
        "Docs: https://pytorch.org/docs/stable/generated/torch.mul.html\n",
        "\n",
        "torch.mul does not perform a matrix multiplication. It broadcasts two tensors and performs an elementwise multiplication. So when you uses it with tensors 1x4 * 4x1 it will work similar to:"
      ],
      "metadata": {
        "id": "5u928cyrcVL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.FloatTensor([[1], [2], [3]])\n",
        "b = torch.FloatTensor([[1, 10, 100, 1000]])\n",
        "a, b = torch.broadcast_tensors(a, b)\n",
        "c = a * b\n",
        "d = torch.mul(a,b)\n",
        "print(a)\n",
        "print(b)\n",
        "assert torch.all(torch.eq(c,d)).item()==True\n",
        "print(c)\n",
        "print(d)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T03:27:55.558708Z",
          "iopub.execute_input": "2023-12-28T03:27:55.559151Z",
          "iopub.status.idle": "2023-12-28T03:27:55.569844Z",
          "shell.execute_reply.started": "2023-12-28T03:27:55.559117Z",
          "shell.execute_reply": "2023-12-28T03:27:55.568693Z"
        },
        "trusted": true,
        "id": "V4c6WYcIcVL7",
        "outputId": "487c07c5-51bf-437f-fe40-156eacbe703e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "tensor([[1., 1., 1., 1.],\n        [2., 2., 2., 2.],\n        [3., 3., 3., 3.]])\ntensor([[   1.,   10.,  100., 1000.],\n        [   1.,   10.,  100., 1000.],\n        [   1.,   10.,  100., 1000.]])\ntensor([[1.0000e+00, 1.0000e+01, 1.0000e+02, 1.0000e+03],\n        [2.0000e+00, 2.0000e+01, 2.0000e+02, 2.0000e+03],\n        [3.0000e+00, 3.0000e+01, 3.0000e+02, 3.0000e+03]])\ntensor([[1.0000e+00, 1.0000e+01, 1.0000e+02, 1.0000e+03],\n        [2.0000e+00, 2.0000e+01, 2.0000e+02, 2.0000e+03],\n        [3.0000e+00, 3.0000e+01, 3.0000e+02, 3.0000e+03]])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    torch.matmul\n",
        "\n",
        "It is better to check out the official documentation https://pytorch.org/docs/stable/generated/torch.matmul.html as it uses different modes depending on the input tensors. It may perform dot product, matrix-matrix product or batched matrix products with broadcasting."
      ],
      "metadata": {
        "id": "8lQiTNjucVL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.randn(10, 3, 4)\n",
        "tensor2 = torch.randn(4)\n",
        "print(tensor1[:,0,0].shape,tensor1[0,:,0].shape,tensor1[0,0,:].shape)\n",
        "print(tensor2.shape)\n",
        "tensor3 = torch.matmul(tensor1,tensor2)\n",
        "print(tensor3.shape)\n",
        "\n",
        "# 3x1x3\n",
        "a = torch.FloatTensor([[[1, 2, 3]], [[3, 4, 5]], [[6, 7, 8]]])\n",
        "# 3\n",
        "b = torch.FloatTensor([1, 10, 100])\n",
        "r1 = torch.matmul(a, b)\n",
        "\n",
        "r2 = torch.stack((\n",
        "    torch.matmul(a[0], b),\n",
        "    torch.matmul(a[1], b),\n",
        "    torch.matmul(a[2], b),\n",
        "))\n",
        "assert torch.allclose(r1, r2)\n",
        "print(a.shape,b.shape,r1.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T03:42:10.890867Z",
          "iopub.execute_input": "2023-12-28T03:42:10.891342Z",
          "iopub.status.idle": "2023-12-28T03:42:10.904673Z",
          "shell.execute_reply.started": "2023-12-28T03:42:10.891305Z",
          "shell.execute_reply": "2023-12-28T03:42:10.903003Z"
        },
        "trusted": true,
        "id": "OjZmqjnQcVL8",
        "outputId": "0f2940d6-0e36-4593-a8dd-9505023cfaca"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "torch.Size([10]) torch.Size([3]) torch.Size([4])\ntorch.Size([4])\ntorch.Size([10, 3])\ntorch.Size([3, 1, 3]) torch.Size([3]) torch.Size([3, 1])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(4, 3, 2)\n",
        "b = torch.rand(   3)     # trying to multiply a * b will give a runtime error\n",
        "c = b.unsqueeze(1)       # change to a 2-dimensional tensor, adding new dim at the end\n",
        "print(\"After broadcasting b : \", c.shape)\n",
        "print(\"Broadcasing internally : \",torch.mul(a,c).shape)            # broadcasting works again!\n",
        "\n",
        "output3d = torch.rand(6, 20, 20)\n",
        "print(\"output3d : \",output3d.shape)\n",
        "\n",
        "input1d = output3d.reshape(6 * 20 * 20)\n",
        "print(\"input1d : \",input1d.shape)\n",
        "\n",
        "# can also call it as a method on the torch module:\n",
        "print(\"same as above but using torch : \",torch.reshape(output3d, (6 * 20 * 20,)).shape)"
      ],
      "metadata": {
        "id": "SUyPu0YZcVL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Common Math function"
      ],
      "metadata": {
        "id": "rnUtWlrhcVL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "# common functions\n",
        "a = torch.rand(2, 4) * 2 - 1\n",
        "print('Common functions:')\n",
        "print(torch.abs(a))\n",
        "print(torch.ceil(a))\n",
        "print(torch.floor(a))\n",
        "print(torch.clamp(a, -0.5, 0.5))\n",
        "\n",
        "# trigonometric functions and their inverses\n",
        "angles = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
        "sines = torch.sin(angles)\n",
        "inverses = torch.asin(sines)\n",
        "print('\\nSine and arcsine:')\n",
        "print(angles)\n",
        "print(sines)\n",
        "print(inverses)\n",
        "\n",
        "# bitwise operations\n",
        "print('\\nBitwise XOR:')\n",
        "b = torch.tensor([1, 5, 11])\n",
        "c = torch.tensor([2, 7, 10])\n",
        "print(torch.bitwise_xor(b, c))\n",
        "\n",
        "# comparisons:\n",
        "print('\\nBroadcasted, element-wise equality comparison:')\n",
        "d = torch.tensor([[1., 2.], [3., 4.]])\n",
        "e = torch.ones(1, 2)  # many comparison ops support broadcasting!\n",
        "print(torch.eq(d, e)) # returns a tensor of type bool\n",
        "\n",
        "# reductions:\n",
        "print('\\nReduction ops:')\n",
        "print(torch.max(d))        # returns a single-element tensor\n",
        "print(torch.max(d).item()) # extracts the value from the returned tensor\n",
        "print(torch.mean(d))       # average\n",
        "print(torch.std(d))        # standard deviation\n",
        "print(torch.prod(d))       # product of all numbers\n",
        "print(torch.unique(torch.tensor([1, 2, 1, 2, 1, 2]))) # filter unique elements\n",
        "\n",
        "# vector and linear algebra operations\n",
        "v1 = torch.tensor([1., 0., 0.])         # x unit vector\n",
        "v2 = torch.tensor([0., 1., 0.])         # y unit vector\n",
        "m1 = torch.rand(2, 2)                   # random matrix\n",
        "m2 = torch.tensor([[3., 0.], [0., 3.]]) # three times identity matrix\n",
        "\n",
        "print('\\nVectors & Matrices:')\n",
        "print(torch.cross(v2, v1)) # negative of z unit vector (v1 x v2 == -v2 x v1)\n",
        "print(m1)\n",
        "m3 = torch.matmul(m1, m2)\n",
        "print(m3)                  # 3 times m1\n",
        "print(torch.svd(m3))       # singular value decomposition"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T01:50:37.961785Z",
          "iopub.execute_input": "2023-12-27T01:50:37.963441Z",
          "iopub.status.idle": "2023-12-27T01:50:38.001452Z",
          "shell.execute_reply.started": "2023-12-27T01:50:37.963395Z",
          "shell.execute_reply": "2023-12-27T01:50:38.000329Z"
        },
        "trusted": true,
        "id": "qaQgjCrscVL9",
        "outputId": "e5edfa90-bd5c-4401-98b9-906df8591bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Common functions:\ntensor([[0.8587, 0.0493, 0.9242, 0.1247],\n        [0.0059, 0.8742, 0.3704, 0.4161]])\ntensor([[-0., -0., 1., -0.],\n        [1., 1., -0., -0.]])\ntensor([[-1., -1.,  0., -1.],\n        [ 0.,  0., -1., -1.]])\ntensor([[-0.5000, -0.0493,  0.5000, -0.1247],\n        [ 0.0059,  0.5000, -0.3704, -0.4161]])\n\nSine and arcsine:\ntensor([0.0000, 0.7854, 1.5708, 2.3562])\ntensor([0.0000, 0.7071, 1.0000, 0.7071])\ntensor([0.0000, 0.7854, 1.5708, 0.7854])\n\nBitwise XOR:\ntensor([3, 2, 1])\n\nBroadcasted, element-wise equality comparison:\ntensor([[ True, False],\n        [False, False]])\n\nReduction ops:\ntensor(4.)\n4.0\ntensor(2.5000)\ntensor(1.2910)\ntensor(24.)\ntensor([1, 2])\n\nVectors & Matrices:\ntensor([ 0.,  0., -1.])\ntensor([[0.1393, 0.9677],\n        [0.4260, 0.3730]])\ntensor([[0.4178, 2.9031],\n        [1.2780, 1.1191]])\ntorch.return_types.svd(\nU=tensor([[-0.8952, -0.4456],\n        [-0.4456,  0.8952]]),\nS=tensor([3.2382, 1.0014]),\nV=tensor([[-0.2914,  0.9566],\n        [-0.9566, -0.2914]]))\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x = torch.arange(1, 11, 1)\n",
        "print(\"Original Tensor:\", x)\n",
        "\n",
        "# Ensure the index tensor is of dtype torch.int64\n",
        "one_hot_encoded = F.one_hot(torch.tensor(x - 1), num_classes=len(x))\n",
        "print(\"One-Hot Encoded Tensor:\\n\", one_hot_encoded.float())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-25T01:58:52.873991Z",
          "iopub.execute_input": "2023-12-25T01:58:52.875131Z",
          "iopub.status.idle": "2023-12-25T01:58:56.959261Z",
          "shell.execute_reply.started": "2023-12-25T01:58:52.875087Z",
          "shell.execute_reply": "2023-12-25T01:58:56.958067Z"
        },
        "trusted": true,
        "id": "Q6l6XpOQcVL-",
        "outputId": "38d80862-c5e9-43b0-ec98-681daf2ab0ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Original Tensor: tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\nOne-Hot Encoded Tensor:\n tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_32/2904155138.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  one_hot_encoded = F.one_hot(torch.tensor(x - 1), num_classes=len(x))\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp = torch.eye(4, 5, requires_grad=True)\n",
        "out = (inp+1).pow(2).t()\n",
        "print(\"inp : \\n\",inp)\n",
        "print(\"out : \\n\",out)\n",
        "out.backward(torch.ones_like(out), retain_graph=True)\n",
        "print(f\"First call\\n{inp.grad}\")\n",
        "out.backward(torch.ones_like(out), retain_graph=True)\n",
        "print(f\"\\nSecond call\\n{inp.grad}\")\n",
        "inp.grad.zero_()\n",
        "out.backward(torch.ones_like(out), retain_graph=True)\n",
        "print(f\"\\nCall after zeroing gradients\\n{inp.grad}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-25T02:00:35.343701Z",
          "iopub.execute_input": "2023-12-25T02:00:35.344091Z",
          "iopub.status.idle": "2023-12-25T02:00:35.358043Z",
          "shell.execute_reply.started": "2023-12-25T02:00:35.34406Z",
          "shell.execute_reply": "2023-12-25T02:00:35.356698Z"
        },
        "trusted": true,
        "id": "MtPVkATOcVL-",
        "outputId": "f0a3e63f-9bc8-4498-dbcd-1948fe5def43"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "inp : \n tensor([[1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0.]], requires_grad=True)\nout : \n tensor([[4., 1., 1., 1.],\n        [1., 4., 1., 1.],\n        [1., 1., 4., 1.],\n        [1., 1., 1., 4.],\n        [1., 1., 1., 1.]], grad_fn=<TBackward0>)\nFirst call\ntensor([[4., 2., 2., 2., 2.],\n        [2., 4., 2., 2., 2.],\n        [2., 2., 4., 2., 2.],\n        [2., 2., 2., 4., 2.]])\n\nSecond call\ntensor([[8., 4., 4., 4., 4.],\n        [4., 8., 4., 4., 4.],\n        [4., 4., 8., 4., 4.],\n        [4., 4., 4., 8., 4.]])\n\nCall after zeroing gradients\ntensor([[4., 2., 2., 2., 2.],\n        [2., 4., 2., 2., 2.],\n        [2., 2., 4., 2., 2.],\n        [2., 2., 2., 4., 2.]])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "class DynamicNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate five parameters and assign them as members.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.a = torch.nn.Parameter(torch.randn(()))\n",
        "        self.b = torch.nn.Parameter(torch.randn(()))\n",
        "        self.c = torch.nn.Parameter(torch.randn(()))\n",
        "        self.d = torch.nn.Parameter(torch.randn(()))\n",
        "        self.e = torch.nn.Parameter(torch.randn(()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        For the forward pass of the model, we randomly choose either 4, 5\n",
        "        and reuse the e parameter to compute the contribution of these orders.\n",
        "\n",
        "        Since each forward pass builds a dynamic computation graph, we can use normal\n",
        "        Python control-flow operators like loops or conditional statements when\n",
        "        defining the forward pass of the model.\n",
        "\n",
        "        Here we also see that it is perfectly safe to reuse the same parameter many\n",
        "        times when defining a computational graph.\n",
        "        \"\"\"\n",
        "        y = self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
        "        for exp in range(4, random.randint(4, 6)):\n",
        "            y = y + self.e * x ** exp\n",
        "        return y\n",
        "\n",
        "    def string(self):\n",
        "        \"\"\"\n",
        "        Just like any class in Python, you can also define custom method on PyTorch modules\n",
        "        \"\"\"\n",
        "        return f'y = {self.a.item()} + {self.b.item()} x + {self.c.item()} x^2 + {self.d.item()} x^3 + {self.e.item()} x^4 ? + {self.e.item()} x^5 ?'\n",
        "\n",
        "\n",
        "# Create Tensors to hold input and outputs.\n",
        "x = torch.linspace(-math.pi, math.pi, 20)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Construct our model by instantiating the class defined above\n",
        "model = DynamicNet()\n",
        "\n",
        "# Construct our loss function and an Optimizer. Training this strange model with\n",
        "# vanilla stochastic gradient descent is tough, so we use momentum\n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-8, momentum=0.9)\n",
        "for t in range(300):\n",
        "    # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_pred, y)\n",
        "    if t % 20 == 0:\n",
        "        print(f\"epoch :{t+1} -> loss : {loss.item()}\")\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(f'Result: {model.string()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCJNP_SaQ8Ey",
        "outputId": "21224b7b-48fc-4d2e-814b-7d0c1e1692e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :1 -> loss : 1681.168701171875\n",
            "epoch :21 -> loss : 1679.867919921875\n",
            "epoch :41 -> loss : 18472.8984375\n",
            "epoch :61 -> loss : 1674.7679443359375\n",
            "epoch :81 -> loss : 2091.922119140625\n",
            "epoch :101 -> loss : 1560.9306640625\n",
            "epoch :121 -> loss : 1389.830078125\n",
            "epoch :141 -> loss : 1360.8319091796875\n",
            "epoch :161 -> loss : 1669.4376220703125\n",
            "epoch :181 -> loss : 1257.3314208984375\n",
            "epoch :201 -> loss : 1205.929443359375\n",
            "epoch :221 -> loss : 1615.4774169921875\n",
            "epoch :241 -> loss : 1728.8299560546875\n",
            "epoch :261 -> loss : 1236.6771240234375\n",
            "epoch :281 -> loss : 1593.4512939453125\n",
            "Result: y = 0.14420916140079498 + -0.5590418577194214 x + -1.822824239730835 x^2 + 0.17527174949645996 x^3 + 0.028357358649373055 x^4 ? + 0.028357358649373055 x^5 ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```python\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "linear_layer = nn.Linear(in_features=10,out_features=5,bias=True)\n",
        "# conv1d -> text,conv2d -> heightXwidth (image),conv3d - heightXweightXtime (video)\n",
        "conv_1d = nn.Conv3d(in_channels=3,out_channels=5,kernel_size=3,stride=2,padding=2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## transformer layer\n",
        "transformer_model = nn.Transformer()\n",
        "# single encoder (embedding_dim=768)\n",
        "encoder_layer = nn.TransformerEncoderLayer(d_model=768,nhead=12)\n",
        "# stacked encoder\n",
        "transformer_encoder = nn.TransformerEncoder(encoder_layer=encoder_layer,num_layers=6)\n",
        "# single decoder layer\n",
        "decoder_layer = nn.TransformerDecoderLayer(d_model=768,nhead=12)\n",
        "# stacked decoder layer\n",
        "transformer_decoder = nn.TransformerDecoder(decoder_layer=decoder_layer,num_layers=6)\n",
        "\n",
        "\n",
        "\n",
        "# lstm cell\n",
        "lstm_cell = nn.LSTMCell(input_size=10,hidden_size=5)\n",
        "# Stack together LSTM cells - 3 stacked cells - similar for GRU\n",
        "lstm_stack = nn.LSTM(input_size=10,hidden_size=5, num_layers=3)\n",
        "bidirectional_lstm_stack = nn.LSTM(input_size=10,hidden_size=5,num_layers=3,bidirectional=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# activation function - relu,sigmoid,softmax\n",
        "# ReLU\n",
        "relu = nn.ReLU()\n",
        "# Sigmoid\n",
        "sigmoid = nn.Sigmoid()\n",
        "# Softmax\n",
        "softmax = nn.Softmax()\n",
        "\n",
        "\n",
        "\n",
        "# loss function\n",
        "# L1Loss\n",
        "loss_fn = nn.L1Loss() # also known as MAE or mean absolute error\n",
        "# MSELoss\n",
        "loss_fn = nn.MSELoss() # also known as MSE or mean squared error\n",
        "# Binary cross entropy (for binary classification problems)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "# Cross entropy (for multi-class classification problems)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "# optimizer\n",
        "model = nn.Transformer()\n",
        "# SGD (stochastic gradient descent)\n",
        "optimizer = torch.optim.SGD(lr=0.1, params=model.parameters())\n",
        "# Adam optimizer\n",
        "optimizer = torch.optim.Adam(lr=0.001, params=model.parameters())\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "-9Oyp4IaR0E9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save & Load Entire Model\n",
        "\n",
        "```python\n",
        "torch.save(model, 'model.pth')\n",
        "model = torch.load('model.pth')\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "```\n",
        "## Save & Load Only the Model State Dict:\n",
        "```python\n",
        "torch.save(model.state_dict(), 'model_state_dict.pth')\n",
        "model = EnhancedRNN(...)  # Initialize the model architecture\n",
        "model.load_state_dict(torch.load('model_state_dict.pth'))\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "```"
      ],
      "metadata": {
        "id": "5JoDnjjtDptg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PTQ - Post training Quantization for Basic Pytorch\n",
        "\n",
        "\n",
        "```python\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    model, {nn.RNN,nn.Linear}, dtype=torch.qint8\n",
        ")\n",
        "\n",
        "\n",
        "EnhancedRNN(\n",
        "  (embedding): Embedding(30522, 128)\n",
        "  (rnn): RNN(128, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
        "  (attention): MultiheadAttention(\n",
        "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
        "  )\n",
        "  (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
        "  (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
        "  (fc1): DynamicQuantizedLinear(in_features=512, out_features=256, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
        "  (fc2): DynamicQuantizedLinear(in_features=256, out_features=2, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
        ")\n",
        "```\n"
      ],
      "metadata": {
        "id": "ttrZLNmGD6je"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Dataset\n",
        "\n",
        "```python\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, features, labels,...):\n",
        "        # features,labels,tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feature = self.features[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(...)\n",
        "        item = {key: torch.squeeze(val) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(label, dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "dataset = CustomDataset() #<class 'list'>\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "# {'input_ids': tensor([[..],[..],..]),\n",
        "#  'attention_mask': tensor([[..],[..],..]),\n",
        "#  'labels': tensor([...])}\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "eamRgEaIETaw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Why do the three LSTM layers have the same dimensions?**\n",
        "\n",
        "The three LSTM layers (`self.lstm1`, `self.lstm2`, and `self.lstm3`) have the same output dimensions (`batch_size, sequence_length, hidden_size`) because they are stacked on top of each other. In this architecture, the output of one LSTM layer is fed as input to the next LSTM layer. Since the hidden state size (`hidden_size`) remains the same across all layers, the output dimensions stay consistent.\n",
        "\n",
        "2. **What is the significance of `num_stacked_layers`?**\n",
        "\n",
        "The `num_stacked_layers` parameter in the LSTM layers determines the number of LSTM cells that are vertically stacked. Each LSTM cell processes the input sequence and passes its output (hidden state and cell state) to the next LSTM cell in the stack. This allows the model to learn more complex representations by capturing long-term dependencies in the input sequence.\n",
        "\n",
        "In the provided code, `num_stacked_layers` is set to 2, which means there are two LSTM cells stacked on top of each other in each of the three LSTM layers (`self.lstm1`, `self.lstm2`, and `self.lstm3`). Increasing the number of stacked layers can potentially improve the model's performance, but it also increases the risk of overfitting and makes the model more computationally expensive.\n",
        "\n",
        "3. **What are `h0` and `c0`?**\n",
        "\n",
        "`h0` and `c0` are the initial hidden state and cell state, respectively, for the LSTM layers. They are required as inputs to the LSTM layers because LSTMs have a recurrent structure that depends on the previous states.\n",
        "\n",
        "- `h0` (initial hidden state): It is a tensor of shape `(num_stacked_layers, batch_size, hidden_size)` that represents the initial hidden state of the LSTM cells. It is typically initialized with zeros.\n",
        "- `c0` (initial cell state): It is a tensor of shape `(num_stacked_layers, batch_size, hidden_size)` that represents the initial cell state of the LSTM cells. It is also typically initialized with zeros.\n",
        "\n",
        "In the provided code, `h0` and `c0` are initialized as zero tensors with the appropriate shapes and are passed to each LSTM layer during the `forward` pass:\n",
        "\n",
        "```python\n",
        "h0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
        "c0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
        "\n",
        "out, _ = self.lstm1(x, (h0, c0))\n",
        "out, _ = self.lstm2(out, (h0, c0))\n",
        "out, _ = self.lstm3(out, (h0, c0))\n",
        "```\n",
        "\n",
        "The initial hidden and cell states are used to kickstart the recurrent computation in the LSTM layers. As the input sequence is processed, the LSTM layers update the hidden and cell states based on the current input and the previous states, capturing the temporal dependencies in the sequence.\n",
        "\n",
        "\n",
        "# Custom RNN model\n",
        "\n",
        "```python\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class EnhancedRNN(nn.Module):\n",
        "    def __init__(self, ...):\n",
        "        super(EnhancedRNN, self).__init__()\n",
        "\n",
        "        # Embedding layer - (vocab_size, embed_dim)\n",
        "        \n",
        "        # RNN layer with multiple layers and bidirectional configuration\n",
        "        # (embed_dim, hidden_dim, num_layers bidirectional=num_directions,dropout,....)\n",
        "\n",
        "        # Multi-Headed Attention - (embed_dim * num_directions,num_heads,...)\n",
        "        \n",
        "        # Layer Normalization - (hidden_dim * num_directions)\n",
        "\n",
        "        # Additional FC layers - (hidden_dim * num_directions,hidden_dim * num_directions) ,\n",
        "        # (hidden_dim * num_directions,output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Embedding - [batch_size, seq_len, embed_dim]\n",
        "\n",
        "        # RNN -  [batch_size, seq_len, hidden_dim * num_directions]\n",
        "        x, _ = self.rnn(x)\n",
        "\n",
        "        # Multi-Headed Attention\n",
        "        x_attn, _ = self.attention(x, x, x)\n",
        "        x = x + x_attn  # Skip connection\n",
        "        x = self.layer_norm1(x)\n",
        "\n",
        "        # Further Processing -  [batch_size, hidden_dim * num_directions]\n",
        "        x = x[:, -1, :]  # Use the output from the last sequence step\n",
        "\n",
        "        # Fully Connected layers - [batch_size, hidden_dim]\n",
        "        return x\n",
        "\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "F0X-gy2BQacq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "7QqviMkDcVMX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}